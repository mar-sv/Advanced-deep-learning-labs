{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56848f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n",
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm \n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.classes = os.listdir(data_dir)\n",
    "        print(self.classes)  # training directories\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.images = []\n",
    "\n",
    "        for class_dir in self.classes:\n",
    "            class_path = os.path.join(data_dir, class_dir)\n",
    "            if os.path.isdir(class_path):\n",
    "                image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                self.images.extend([(os.path.join(class_path, f), self.class_to_idx[class_dir]) for f in image_files])\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),  # Resize to a fixed size\n",
    "            transforms.ToTensor(),  # Convert to PyTorch tensor\n",
    "            transforms.Normalize(mean=[0.485], std=[0.229])  # Normalize \n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.images[idx]\n",
    "        try:\n",
    "            with open(image_path, 'rb') as file:\n",
    "                image = Image.open(file)\n",
    "                if image.mode != 'L':\n",
    "                    image = image.convert('L')  # Convert to grayscale\n",
    "                if self.transform:\n",
    "                    tensor_image = self.transform(image)\n",
    "                else:\n",
    "                    tensor_image = image\n",
    "                return tensor_image, label\n",
    "        except Exception as e:\n",
    "            \n",
    "            raise ValueError(f'Path or data is wrong {e}')\n",
    "\n",
    "train_path = \"train\" # Update directory path - preferrably put the code with the data\n",
    "val_path = \"val\"\n",
    "\n",
    "\n",
    "# instance of custom dataset\n",
    "train_dataset = MyDataset(train_path)\n",
    "val_dataset = MyDataset(val_path)\n",
    "\n",
    "# parameters for DataLoader\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "num_workers = 0  # Adjust this based on your system's capabilities, 4 if system is good\n",
    "\n",
    "# DataLoader instance\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "#for batch_idx in train_loader:\n",
    "    #print(batch_idx)\n",
    "    \n",
    "        \n",
    "    # Process your image data batch here\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b8591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2aa3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "\n",
    "\n",
    "#Define some activation functions\n",
    "activation_functions = {\n",
    "    'relu': F.relu,\n",
    "    'sigmoid': torch.sigmoid,\n",
    "    'tanh': torch.tanh,\n",
    "    'leaky_relu': F.leaky_relu,\n",
    "    'elu': F.elu,\n",
    "}\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "        super(Net, self).__init__()\n",
    "        in_size = 256\n",
    "\n",
    "            # Define the model parameters and other hyperparameters\n",
    "        #Number of layers\n",
    "        num_conv_layers = trial.suggest_int('num_conv_layers', 2, 4)\n",
    "        #Number of filters\n",
    "        num_filters = [trial.suggest_int('num_filters_{}'.format(i), 16, 128) for i in range(num_conv_layers)]\n",
    "        #Number of neurons\n",
    "        num_neurons = trial.suggest_int('num_neurons', 100, 500)\n",
    "        #Dropout of conv2 (if applicable)\n",
    "        drop_conv2 = trial.suggest_uniform('drop_conv2', 0.0, 0.5)\n",
    "        #Dropout of the first connected layer\n",
    "        drop_fc1 = trial.suggest_uniform('drop_fc1', 0.0, 0.5)\n",
    "\n",
    "        # Suggest activation functions (used in forward pass, here a name is given that will be used in the dict above)\n",
    "        self.conv_activation_name = trial.suggest_categorical('conv_activation', list(activation_functions.keys()))\n",
    "        self.fc_activation_name = trial.suggest_categorical('fc_activation', list(activation_functions.keys()))\n",
    "\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, num_filters[0], kernel_size=(3, 3))])\n",
    "        out_size = in_size - 2  # 3 - 1 for kernel size minus 1\n",
    "        out_size = out_size // 2\n",
    "\n",
    "        for i in range(1, num_conv_layers):\n",
    "            self.convs.append(nn.Conv2d(num_filters[i-1], num_filters[i], kernel_size=(3, 3)))\n",
    "            out_size = (out_size - 2) // 2\n",
    "\n",
    "        self.conv2_drop = nn.Dropout2d(p=drop_conv2)\n",
    "        self.out_feature = num_filters[-1] * out_size * out_size\n",
    "        self.fc1 = nn.Linear(self.out_feature, num_neurons)\n",
    "        self.fc2 = nn.Linear(num_neurons, 1)\n",
    "        self.p1 = drop_fc1\n",
    "\n",
    "        # Initialize weights\n",
    "        for conv in self.convs:\n",
    "            nn.init.kaiming_normal_(conv.weight, nonlinearity='relu')\n",
    "            if conv.bias is not None:\n",
    "                nn.init.constant_(conv.bias, 0)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_activation = activation_functions[self.conv_activation_name]\n",
    "        fc_activation = activation_functions[self.fc_activation_name]\n",
    "\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x)\n",
    "            x = conv_activation(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "            if i == 2:\n",
    "                x = self.conv2_drop(x)\n",
    "\n",
    "        x = x.view(-1, self.out_feature)\n",
    "        x = fc_activation(self.fc1(x))\n",
    "        x = F.dropout(x, p=self.p1, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.BCELoss()  # Use Binary Cross Entropy Loss for binary classification\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.float().unsqueeze(1)  # Ensure target is the correct shape and type\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "    \n",
    "    print('Loss: {:.6f}, Epoch: {}'.format(loss.item(),epoch))                                   \n",
    "\n",
    "\n",
    "def test_model(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    criterion = nn.BCELoss()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            target = target.float()\n",
    "            output = output.view(-1)\n",
    "            test_loss += criterion(output, target)\n",
    "            # Binary classification prediction\n",
    "            pred = (output > 0.5).float()  # Thresholding at 0.5\n",
    "            correct += pred.eq(target).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    #Load data\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "    #Choose cuda if available, else cpu. \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "\n",
    "    #Only 10 for hyperparameter tuning\n",
    "    num_epochs = 10\n",
    "\n",
    "    #load data\n",
    "    model = Net(trial).to(device)\n",
    "\n",
    "        # Generate the optimizers\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)                               \n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "        # Training of the model\n",
    "    for epoch in range(num_epochs):\n",
    "        train_model(model, device, train_loader, optimizer, epoch)  # Train the model\n",
    "        accuracy = test_model(model, device, val_loader)   # Evaluate the model\n",
    "\n",
    "        # For pruning (stops trial early if not promising)\n",
    "        trial.report(accuracy, epoch)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    trial.set_user_attr('model', model)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adefe2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-15 21:09:54,210] A new study created in memory with name: no-name-1c4e60de-fb83-40d4-bb57-0c9f6beed22b\n",
      "C:\\Users\\masv\\AppData\\Local\\Temp\\ipykernel_22316\\494596573.py:34: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  drop_conv2 = trial.suggest_uniform('drop_conv2', 0.0, 0.5)\n",
      "C:\\Users\\masv\\AppData\\Local\\Temp\\ipykernel_22316\\494596573.py:36: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  drop_fc1 = trial.suggest_uniform('drop_fc1', 0.0, 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 31.250000, Epoch: 0\n",
      "\n",
      "Test set: Average loss: 3.1250, Accuracy: 8/16 (50%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-15 21:20:28,964] Trial 0 finished with value: 50.0 and parameters: {'num_conv_layers': 2, 'num_filters_0': 98, 'num_filters_1': 111, 'num_neurons': 813, 'drop_conv2': 0.08152126297232581, 'drop_fc1': 0.46066056740821915, 'conv_activation': 'relu', 'fc_activation': 'leaky_relu', 'optimizer': 'RMSprop', 'lr': 0.0009449630558906713}. Best is trial 0 with value: 50.0.\n",
      "[W 2024-05-15 21:20:43,072] Trial 1 failed with parameters: {'num_conv_layers': 4, 'num_filters_0': 49, 'num_filters_1': 52, 'num_filters_2': 30, 'num_filters_3': 19, 'num_neurons': 860, 'drop_conv2': 0.19181357997200632, 'drop_fc1': 0.237740202698265, 'conv_activation': 'leaky_relu', 'fc_activation': 'sigmoid', 'optimizer': 'RMSprop', 'lr': 0.00034136150110160746} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\masv\\AppData\\Local\\Temp\\ipykernel_22316\\494596573.py\", line 143, in objective\n",
      "    train_model(model, device, train_loader, optimizer, epoch)  # Train the model\n",
      "  File \"C:\\Users\\masv\\AppData\\Local\\Temp\\ipykernel_22316\\494596573.py\", line 91, in train_model\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\torch\\_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-05-15 21:20:43,076] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m         torch\u001b[38;5;241m.\u001b[39msave(best_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_2.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n",
      "File \u001b[1;32mc:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[32], line 143\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# Training of the model\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m--> 143\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m test_model(model, device, val_loader)   \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# For pruning (stops trial early if not promising)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[32], line 91\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     89\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m     90\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m---> 91\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m, Epoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss\u001b[38;5;241m.\u001b[39mitem(),epoch))\n",
      "File \u001b[1;32mc:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\masv\\AppData\\Local\\miniforge3\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def save_best_model(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        best_model = trial.user_attrs['model']\n",
    "        torch.save(best_model, 'best_model_2.pth')\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30, callbacks=[save_best_model])\n",
    "\n",
    "print(\"Best hyperparameters: \", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d509f85",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m,map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[0;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m test_model(model,device,val_loader)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model = torch.load('best_model.pth',map_location=torch.device('cpu'))\n",
    "#model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_model(model,device,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79bc1d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('convs.0.weight',\n",
       "              tensor([[[[ 0.1228,  0.0830, -0.1227],\n",
       "                        [-0.0631,  0.1482,  0.3272],\n",
       "                        [-0.0465,  0.2329, -0.4346]],\n",
       "              \n",
       "                       [[-0.3679, -0.0526, -0.2006],\n",
       "                        [-0.4310,  0.4524,  0.0892],\n",
       "                        [ 0.2695, -0.0429,  0.5000]],\n",
       "              \n",
       "                       [[-0.3989,  0.0224, -0.3173],\n",
       "                        [-0.0816,  0.5339, -0.0816],\n",
       "                        [-0.5659, -0.1707, -0.1542]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0384,  0.0640, -0.4782],\n",
       "                        [ 0.2421,  0.2640, -0.0802],\n",
       "                        [ 0.3875,  0.6002,  0.4804]],\n",
       "              \n",
       "                       [[-0.0506, -0.2102, -0.3600],\n",
       "                        [ 0.2909, -0.2469,  0.4300],\n",
       "                        [ 0.1046,  0.2658,  0.0199]],\n",
       "              \n",
       "                       [[-0.2797, -0.3294, -0.3609],\n",
       "                        [-0.1673,  0.3917,  0.0473],\n",
       "                        [ 0.1262, -0.3772, -0.3466]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1057,  0.1962, -0.0934],\n",
       "                        [ 0.1529, -0.1532,  0.1648],\n",
       "                        [ 0.0776,  0.2289,  0.0858]],\n",
       "              \n",
       "                       [[-0.3200,  0.5177, -0.2640],\n",
       "                        [ 0.0653,  0.0469, -0.0305],\n",
       "                        [ 0.1216,  0.0566, -0.0174]],\n",
       "              \n",
       "                       [[-0.0126,  0.0295, -0.4262],\n",
       "                        [-0.0169, -0.3707, -0.2147],\n",
       "                        [ 0.2017, -0.0627, -0.0125]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.1390, -0.0345, -0.4674],\n",
       "                        [ 0.4566, -0.3601, -0.2606],\n",
       "                        [ 0.4384, -0.4839, -0.2937]],\n",
       "              \n",
       "                       [[-0.2535,  0.0144, -0.2556],\n",
       "                        [-0.0500,  0.0421,  0.0744],\n",
       "                        [ 0.0284,  0.1025,  0.3042]],\n",
       "              \n",
       "                       [[-0.2826, -0.4935, -0.0837],\n",
       "                        [ 0.0282, -0.2934, -0.1080],\n",
       "                        [-0.2365, -0.1868,  0.1324]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0032,  0.0895,  0.0575],\n",
       "                        [ 0.0893, -0.1560, -0.0070],\n",
       "                        [-0.4261,  0.2358,  0.1927]],\n",
       "              \n",
       "                       [[-0.2897,  0.3743, -0.1888],\n",
       "                        [-0.1679,  0.0806, -0.4103],\n",
       "                        [-0.2083, -0.0123,  0.1548]],\n",
       "              \n",
       "                       [[ 0.1044, -0.0649, -0.1656],\n",
       "                        [ 0.0095,  0.1731, -0.3648],\n",
       "                        [ 0.3320,  0.0032,  0.1792]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.5674,  0.3324, -0.0502],\n",
       "                        [ 0.2382,  0.1296, -0.0050],\n",
       "                        [-0.2441,  0.4117,  0.7134]],\n",
       "              \n",
       "                       [[ 0.0950,  0.1229,  0.4670],\n",
       "                        [ 0.1679,  0.2893, -0.2804],\n",
       "                        [-0.1004,  0.2017, -0.1739]],\n",
       "              \n",
       "                       [[-0.2250, -0.1199,  0.2755],\n",
       "                        [ 0.3530, -0.6327,  0.0825],\n",
       "                        [-0.2290,  0.3086, -0.1519]]]])),\n",
       "             ('convs.0.bias',\n",
       "              tensor([-3.1361e-03,  6.5310e-03,  1.7421e-02, -5.6643e-03, -2.5650e-03,\n",
       "                      -2.5839e-03, -3.0466e-03, -9.3859e-04,  2.4600e-03, -1.1525e-03,\n",
       "                      -9.7263e-03,  1.0597e-03, -7.5889e-03,  4.5989e-03,  2.7862e-03,\n",
       "                      -5.7669e-03,  4.3531e-03, -3.7761e-03, -1.0797e-02,  1.3265e-03,\n",
       "                      -4.5159e-03,  1.1683e-03, -7.4659e-03, -5.3794e-03,  2.2574e-04,\n",
       "                      -7.5661e-03, -6.4712e-03, -7.1249e-03,  6.0772e-05, -7.8538e-03,\n",
       "                      -4.7994e-03,  3.3134e-03, -6.7079e-04,  1.2148e-03, -3.4720e-03,\n",
       "                       2.1831e-03, -1.6721e-03, -2.0880e-03, -1.8040e-03,  1.3247e-03,\n",
       "                       3.2531e-04, -1.5423e-02, -6.0836e-03,  2.4133e-03,  5.6535e-03,\n",
       "                       6.3069e-03,  3.8157e-03, -1.8156e-03, -9.0757e-03, -3.3849e-04,\n",
       "                      -4.1702e-03,  4.8219e-03, -1.9504e-04, -6.2802e-03, -5.4316e-03,\n",
       "                      -7.2833e-03,  3.2613e-03,  1.3940e-03, -7.5792e-03, -1.0205e-03,\n",
       "                      -1.2583e-02,  6.6366e-05, -5.1526e-03,  3.5561e-03,  7.8158e-04,\n",
       "                       7.5649e-03, -1.7851e-03,  6.1363e-03,  6.3057e-03,  7.2096e-03,\n",
       "                      -3.8320e-03, -2.5471e-03, -7.6033e-03,  4.6013e-03, -3.1592e-03,\n",
       "                      -5.6297e-03,  3.5633e-03, -1.1238e-02])),\n",
       "             ('convs.1.weight',\n",
       "              tensor([[[[-1.8760e-02, -2.4626e-02,  3.6737e-02],\n",
       "                        [-5.8427e-02,  2.3367e-04, -3.4438e-03],\n",
       "                        [-3.2452e-02,  2.0347e-02,  5.2839e-02]],\n",
       "              \n",
       "                       [[ 8.0709e-02,  1.2697e-01,  1.1887e-02],\n",
       "                        [ 1.5122e-02,  7.3664e-02, -1.1826e-02],\n",
       "                        [-7.1431e-02,  9.6969e-02, -7.6888e-02]],\n",
       "              \n",
       "                       [[ 4.9677e-02,  9.3230e-02,  4.6424e-02],\n",
       "                        [ 9.0609e-02, -6.9909e-02,  1.1167e-01],\n",
       "                        [-1.0375e-02,  1.1680e-01, -3.0767e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4770e-02,  6.9352e-02,  2.9616e-02],\n",
       "                        [ 1.6607e-02,  5.4223e-03,  6.0148e-03],\n",
       "                        [ 3.9368e-02,  1.4790e-02,  1.6439e-02]],\n",
       "              \n",
       "                       [[ 1.3163e-01, -5.0858e-02,  5.7037e-02],\n",
       "                        [-4.0278e-02, -1.9961e-03,  2.6715e-02],\n",
       "                        [ 2.1693e-02, -7.6003e-02,  3.6766e-02]],\n",
       "              \n",
       "                       [[ 8.4201e-03,  3.1485e-02, -1.4391e-01],\n",
       "                        [-8.0383e-02,  1.3117e-02,  9.2098e-02],\n",
       "                        [-2.6050e-02,  8.0637e-02,  1.7249e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.1688e-02, -7.3975e-03, -1.1564e-02],\n",
       "                        [-8.8791e-02,  8.8240e-02,  1.2290e-01],\n",
       "                        [-3.5632e-02,  8.7477e-02,  3.4021e-02]],\n",
       "              \n",
       "                       [[-2.5828e-02,  9.3019e-02,  9.7186e-03],\n",
       "                        [-6.2678e-02,  4.9119e-02,  2.3697e-02],\n",
       "                        [ 5.4163e-02, -4.8175e-02, -1.3941e-02]],\n",
       "              \n",
       "                       [[ 4.4571e-03,  1.4632e-02,  3.0885e-02],\n",
       "                        [-1.7237e-02, -6.7303e-02,  2.7466e-02],\n",
       "                        [ 2.0195e-02, -2.2664e-02, -1.6715e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.9130e-02, -1.2627e-02,  9.2583e-02],\n",
       "                        [-1.0502e-01, -5.7673e-02, -1.3478e-02],\n",
       "                        [ 1.7093e-02, -1.2332e-02, -1.9367e-02]],\n",
       "              \n",
       "                       [[-4.5195e-02,  2.5647e-03,  3.9463e-02],\n",
       "                        [ 4.9132e-02, -2.2460e-03, -4.0329e-02],\n",
       "                        [-5.5479e-03, -5.4575e-03, -1.3259e-01]],\n",
       "              \n",
       "                       [[-1.2418e-02, -1.0132e-01,  1.4927e-02],\n",
       "                        [-1.5037e-02, -1.0270e-02,  9.2474e-03],\n",
       "                        [ 7.5331e-02,  6.8468e-02,  4.3306e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.4491e-02, -3.9156e-02, -1.5294e-02],\n",
       "                        [ 7.3076e-02,  3.9242e-02,  1.6658e-02],\n",
       "                        [ 7.3557e-03, -8.1711e-02,  1.2469e-02]],\n",
       "              \n",
       "                       [[ 1.0057e-02,  8.4286e-02, -6.8317e-03],\n",
       "                        [ 9.4040e-02, -3.1069e-02, -3.4949e-02],\n",
       "                        [-5.0286e-02,  1.6099e-02,  4.8198e-02]],\n",
       "              \n",
       "                       [[ 5.9289e-02,  5.2038e-02,  5.7561e-03],\n",
       "                        [ 2.0627e-02,  8.7219e-02, -1.0960e-02],\n",
       "                        [ 1.1163e-01,  1.8445e-02,  6.4113e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.9831e-02,  1.4411e-02,  3.0941e-02],\n",
       "                        [-1.0967e-01, -8.7752e-02,  1.7933e-02],\n",
       "                        [-4.5493e-02, -1.1007e-01, -1.3836e-01]],\n",
       "              \n",
       "                       [[ 6.9210e-03,  7.8742e-02, -5.8384e-03],\n",
       "                        [-1.8460e-04,  1.3786e-02,  4.8943e-02],\n",
       "                        [-7.5699e-04,  7.7922e-02,  5.2092e-02]],\n",
       "              \n",
       "                       [[-7.2823e-02, -1.2232e-02,  1.0131e-02],\n",
       "                        [ 3.4400e-03,  2.9629e-02,  6.8291e-02],\n",
       "                        [ 5.1870e-02,  1.2049e-02,  4.8918e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 5.8861e-02,  2.3423e-02, -1.9271e-02],\n",
       "                        [-2.3772e-02,  5.3078e-02, -3.7336e-03],\n",
       "                        [ 4.0041e-03,  8.6323e-03, -5.1982e-02]],\n",
       "              \n",
       "                       [[ 2.7272e-03,  1.5390e-02,  4.5777e-02],\n",
       "                        [ 5.7882e-02, -3.7749e-02,  2.2137e-02],\n",
       "                        [-1.4580e-02,  9.5703e-02, -5.0646e-02]],\n",
       "              \n",
       "                       [[ 1.2043e-02, -4.1938e-02,  7.3000e-02],\n",
       "                        [ 1.5935e-02,  6.8615e-02, -2.8988e-02],\n",
       "                        [ 2.9126e-02,  1.0036e-01,  1.3195e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.9025e-03,  1.3878e-02, -5.2698e-02],\n",
       "                        [-5.4877e-02,  5.2059e-02, -4.2342e-02],\n",
       "                        [ 5.4462e-02, -6.3165e-02,  8.5986e-03]],\n",
       "              \n",
       "                       [[-6.7258e-02,  8.8936e-02, -5.2479e-02],\n",
       "                        [-7.9943e-03, -5.4733e-02, -7.4829e-02],\n",
       "                        [ 8.7398e-02, -7.5202e-02, -2.8513e-02]],\n",
       "              \n",
       "                       [[-4.7621e-02, -6.1335e-02,  5.3833e-03],\n",
       "                        [-2.1600e-02, -2.2060e-02,  5.1288e-02],\n",
       "                        [ 1.2357e-02,  4.3027e-02, -2.1407e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.1756e-05,  2.8016e-02,  1.9947e-02],\n",
       "                        [-3.1829e-02, -1.1947e-01, -3.7547e-02],\n",
       "                        [-2.9958e-02,  2.3130e-02,  9.2691e-03]],\n",
       "              \n",
       "                       [[ 2.2045e-02,  2.1349e-03,  1.6475e-02],\n",
       "                        [ 4.5779e-02, -5.7685e-02, -1.4705e-02],\n",
       "                        [-4.2582e-02, -1.7011e-03,  7.3021e-02]],\n",
       "              \n",
       "                       [[-2.6435e-02,  3.6648e-02, -4.1605e-02],\n",
       "                        [ 4.4516e-02,  5.4109e-02,  1.0144e-01],\n",
       "                        [ 6.2888e-02,  2.2954e-02,  3.4263e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.6191e-02,  1.1063e-02,  1.0271e-01],\n",
       "                        [-1.0062e-01, -3.7362e-02,  1.4820e-03],\n",
       "                        [ 1.3466e-02, -9.4416e-02,  4.7041e-02]],\n",
       "              \n",
       "                       [[ 4.4617e-02, -3.2948e-02,  9.4052e-02],\n",
       "                        [ 3.0511e-02,  2.3649e-02,  1.2350e-02],\n",
       "                        [-4.1356e-02, -3.6037e-02, -1.1091e-01]],\n",
       "              \n",
       "                       [[-1.0682e-02, -2.2604e-02, -5.7985e-02],\n",
       "                        [-2.9263e-03,  3.3310e-03, -8.7325e-03],\n",
       "                        [-8.8699e-02, -2.2666e-02, -3.6878e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4508e-02,  3.9874e-02, -3.7549e-02],\n",
       "                        [ 3.6392e-02, -8.8541e-02, -8.2573e-02],\n",
       "                        [ 2.2943e-02,  8.3701e-03,  1.1748e-01]],\n",
       "              \n",
       "                       [[-8.5722e-03,  9.7191e-02,  3.9781e-02],\n",
       "                        [-7.3726e-02,  6.5402e-02,  8.6522e-02],\n",
       "                        [-4.6702e-02, -2.1220e-02,  5.2303e-02]],\n",
       "              \n",
       "                       [[ 7.5468e-02,  2.2544e-02, -3.5103e-02],\n",
       "                        [-1.1920e-01, -4.3839e-02,  3.6398e-02],\n",
       "                        [-2.2268e-02,  2.8875e-02,  2.9974e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4007e-02,  7.2769e-02,  1.6124e-02],\n",
       "                        [-3.0526e-02, -1.3922e-01,  3.3486e-02],\n",
       "                        [-5.4477e-02,  3.1332e-02, -3.3377e-02]],\n",
       "              \n",
       "                       [[ 1.9331e-02,  1.9583e-02,  1.0789e-02],\n",
       "                        [-1.0827e-02, -4.2422e-02,  8.4389e-02],\n",
       "                        [ 1.4156e-02, -1.1570e-01, -3.4706e-02]],\n",
       "              \n",
       "                       [[-1.0206e-01,  2.1899e-02, -2.7608e-02],\n",
       "                        [-5.1862e-02, -5.6256e-03,  9.7540e-03],\n",
       "                        [ 5.5851e-02, -6.8791e-02,  2.4592e-02]]]])),\n",
       "             ('convs.1.bias',\n",
       "              tensor([-9.8448e-03, -2.9894e-03, -1.6174e-03, -1.2100e-03, -1.7515e-03,\n",
       "                      -2.5196e-03,  4.0230e-04, -3.0202e-03,  5.5385e-03, -4.8621e-03,\n",
       "                       1.6954e-04, -6.5042e-03, -4.3185e-03, -7.7025e-03,  4.2372e-03,\n",
       "                      -1.7480e-03, -5.3900e-03,  8.1931e-03, -3.0075e-03, -1.1081e-02,\n",
       "                       6.3124e-04,  4.3140e-03, -2.9021e-03,  2.5044e-05, -3.6560e-03,\n",
       "                      -4.3927e-03, -6.9471e-03, -4.7475e-03, -1.0366e-03, -1.2790e-03,\n",
       "                      -2.7073e-03, -3.9871e-03, -9.1518e-03, -9.1896e-03, -7.7687e-03,\n",
       "                       2.4403e-03,  2.4403e-03,  8.2367e-05, -1.7653e-03,  3.6616e-03,\n",
       "                      -2.2395e-04, -2.7216e-03, -6.7577e-03, -3.1088e-03, -7.4809e-03,\n",
       "                      -1.9869e-03, -3.6882e-03,  6.9819e-06, -4.9825e-03, -3.8018e-03,\n",
       "                      -6.5798e-03,  2.1339e-03, -4.8049e-04, -1.6617e-03, -2.0222e-03,\n",
       "                       3.7683e-03, -1.0293e-02, -2.8359e-03, -5.3202e-03,  2.9115e-03,\n",
       "                      -2.3435e-03, -4.8116e-04, -5.2282e-03, -4.6207e-03, -3.7597e-03])),\n",
       "             ('convs.2.weight',\n",
       "              tensor([[[[ 6.1352e-02,  1.7595e-02, -8.1727e-02],\n",
       "                        [ 2.0664e-02, -1.4302e-02,  4.3175e-03],\n",
       "                        [ 5.9363e-03, -1.0133e-01,  6.3929e-02]],\n",
       "              \n",
       "                       [[-2.4820e-02, -9.0045e-02,  5.9096e-02],\n",
       "                        [ 6.7479e-02, -3.8882e-03,  1.3788e-01],\n",
       "                        [-4.5805e-02,  5.0586e-02,  4.6880e-02]],\n",
       "              \n",
       "                       [[-6.4368e-02,  9.7194e-02, -5.8482e-03],\n",
       "                        [-1.6132e-01,  2.5423e-02, -1.9938e-02],\n",
       "                        [-2.2311e-02,  5.1535e-02, -1.2565e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7832e-01, -7.8821e-02,  4.9237e-02],\n",
       "                        [-7.9377e-02, -1.4651e-01,  6.8132e-02],\n",
       "                        [-6.6551e-02,  6.1785e-03,  4.7962e-03]],\n",
       "              \n",
       "                       [[ 6.4667e-03,  1.2320e-02, -9.3981e-03],\n",
       "                        [-1.1890e-01,  1.3007e-01, -5.7702e-02],\n",
       "                        [-3.3304e-02, -2.4225e-02, -4.1777e-02]],\n",
       "              \n",
       "                       [[-2.9295e-04, -4.9460e-02, -3.7001e-02],\n",
       "                        [ 3.7696e-02,  6.6487e-02, -4.7132e-02],\n",
       "                        [-4.1887e-02, -8.0874e-02,  1.2022e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9291e-02,  2.2305e-03, -4.1926e-02],\n",
       "                        [-5.6508e-02, -5.8589e-02, -2.5638e-03],\n",
       "                        [ 9.6511e-02,  7.7087e-02,  9.8330e-02]],\n",
       "              \n",
       "                       [[ 7.3976e-03, -2.7074e-02,  7.0364e-02],\n",
       "                        [-1.8952e-01, -4.1873e-02, -6.3660e-03],\n",
       "                        [-6.6114e-02,  2.6978e-02, -5.0297e-02]],\n",
       "              \n",
       "                       [[-2.8684e-03,  2.5447e-02, -2.4414e-02],\n",
       "                        [ 1.6630e-02,  3.9396e-02,  4.0866e-02],\n",
       "                        [ 4.7108e-02,  2.6101e-02,  1.5107e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.7991e-02, -8.5355e-02,  3.7789e-02],\n",
       "                        [-8.5774e-02,  1.5724e-01, -3.2859e-02],\n",
       "                        [ 9.3688e-02, -9.9265e-02,  6.3563e-02]],\n",
       "              \n",
       "                       [[ 1.8490e-02,  5.8421e-02, -2.4232e-02],\n",
       "                        [ 8.4514e-02, -7.6346e-03,  2.7765e-02],\n",
       "                        [ 2.8408e-02,  2.8509e-02,  8.0158e-03]],\n",
       "              \n",
       "                       [[ 6.5820e-02,  7.7127e-04, -6.8141e-03],\n",
       "                        [-5.0217e-02,  6.3025e-03, -6.3996e-04],\n",
       "                        [ 1.4638e-02, -2.8809e-02, -4.5708e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.9109e-02, -7.3185e-03,  1.7499e-02],\n",
       "                        [ 1.1424e-02, -2.9112e-02, -1.0417e-02],\n",
       "                        [ 5.9768e-02,  5.3442e-02,  2.8642e-02]],\n",
       "              \n",
       "                       [[-8.6617e-03, -7.4339e-02, -1.8774e-02],\n",
       "                        [ 1.0737e-02, -3.8409e-02, -2.2458e-02],\n",
       "                        [ 3.4556e-02, -1.0845e-01,  6.5710e-02]],\n",
       "              \n",
       "                       [[ 2.5593e-02,  1.6754e-02, -2.7755e-02],\n",
       "                        [-6.0230e-03,  9.8142e-02, -3.4400e-02],\n",
       "                        [-8.8875e-02, -7.6232e-02,  6.2356e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1367e-03,  4.8301e-02, -2.8137e-02],\n",
       "                        [ 7.6507e-02,  5.3565e-03, -2.1191e-02],\n",
       "                        [-2.7338e-02, -3.2980e-03, -4.8863e-02]],\n",
       "              \n",
       "                       [[ 1.7027e-03, -5.1938e-02,  4.7484e-02],\n",
       "                        [ 4.4446e-02, -9.0362e-02, -7.0831e-02],\n",
       "                        [-2.1474e-03,  7.8021e-03,  1.4436e-02]],\n",
       "              \n",
       "                       [[ 6.1100e-02, -6.1669e-02,  1.1692e-01],\n",
       "                        [-5.5967e-02, -7.2214e-02, -5.8287e-02],\n",
       "                        [ 3.0521e-02,  2.8572e-02, -8.6229e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-2.8123e-02, -5.3833e-03, -2.4781e-02],\n",
       "                        [ 1.1157e-01,  6.7905e-02,  9.7213e-03],\n",
       "                        [ 1.7313e-02, -4.3176e-02,  1.6713e-02]],\n",
       "              \n",
       "                       [[ 5.4845e-03,  1.2980e-01, -1.1898e-02],\n",
       "                        [ 4.7345e-02,  1.7222e-02,  2.0133e-02],\n",
       "                        [ 1.9361e-02,  1.1936e-02,  4.6688e-02]],\n",
       "              \n",
       "                       [[-5.9708e-02,  3.4519e-02,  1.9305e-04],\n",
       "                        [-1.9793e-02, -1.1702e-01, -4.2595e-02],\n",
       "                        [-1.7698e-02,  1.1533e-02, -6.3206e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2694e-02,  9.0467e-02,  1.0228e-01],\n",
       "                        [-9.4560e-02, -5.9937e-02, -2.4105e-02],\n",
       "                        [-9.7450e-02, -3.3195e-02, -7.5213e-02]],\n",
       "              \n",
       "                       [[-2.1159e-02, -8.0148e-02, -3.3240e-02],\n",
       "                        [-4.4975e-02,  7.2263e-02, -7.1358e-03],\n",
       "                        [-2.8022e-03, -2.1218e-02,  1.1761e-01]],\n",
       "              \n",
       "                       [[-7.5389e-02, -4.9699e-02,  4.8896e-02],\n",
       "                        [-1.0975e-01, -8.5872e-02, -9.7621e-02],\n",
       "                        [ 1.2830e-02,  9.4610e-03, -4.4565e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.0561e-02,  5.9700e-02,  7.0852e-02],\n",
       "                        [ 3.9808e-02, -2.0805e-02,  1.0790e-01],\n",
       "                        [ 8.4318e-02,  1.0736e-02, -2.2177e-02]],\n",
       "              \n",
       "                       [[-8.6003e-02,  6.4961e-02, -5.3484e-02],\n",
       "                        [-9.7712e-02, -3.4549e-02, -7.6608e-03],\n",
       "                        [ 8.5906e-02,  4.4525e-02,  4.3027e-02]],\n",
       "              \n",
       "                       [[-1.4836e-02,  8.0346e-02, -8.6760e-03],\n",
       "                        [ 4.5310e-02, -3.7152e-02,  1.0294e-02],\n",
       "                        [-3.7975e-02, -6.0782e-02, -1.7093e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.2670e-03, -3.7122e-02, -1.2632e-01],\n",
       "                        [ 3.0343e-02, -6.4155e-02, -3.4224e-02],\n",
       "                        [-1.2004e-02, -9.2094e-03, -2.9022e-02]],\n",
       "              \n",
       "                       [[-1.0348e-04, -1.6049e-02,  2.6820e-02],\n",
       "                        [-8.5088e-02,  3.4991e-03, -4.0537e-02],\n",
       "                        [ 5.0987e-02, -5.2555e-03,  4.7835e-02]],\n",
       "              \n",
       "                       [[ 3.9947e-03, -2.8545e-02,  2.8471e-02],\n",
       "                        [ 5.8874e-02, -4.2895e-02,  1.0365e-01],\n",
       "                        [ 1.8086e-02, -3.4985e-02,  6.8355e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0906e-02,  3.2002e-02,  5.1272e-02],\n",
       "                        [ 5.7547e-02, -6.0207e-03, -2.8998e-02],\n",
       "                        [-1.0514e-01,  8.5593e-02, -2.4591e-02]],\n",
       "              \n",
       "                       [[-5.7387e-03,  6.1895e-02, -1.1910e-01],\n",
       "                        [-5.8477e-02,  6.7541e-02,  6.2283e-02],\n",
       "                        [ 1.2311e-02,  1.4211e-01, -1.0696e-02]],\n",
       "              \n",
       "                       [[-9.0153e-02, -5.4740e-02,  8.9946e-02],\n",
       "                        [-3.9257e-02,  5.1647e-02,  4.2906e-02],\n",
       "                        [ 3.1329e-03,  6.1982e-02, -2.6926e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0411e-01,  1.5681e-02, -1.7152e-02],\n",
       "                        [-5.0350e-02,  7.4829e-02,  1.6627e-02],\n",
       "                        [-1.1148e-01,  2.8377e-02, -6.4854e-02]],\n",
       "              \n",
       "                       [[-3.3093e-02, -1.0515e-01, -5.5436e-02],\n",
       "                        [-2.2017e-02,  1.0844e-01,  5.5534e-02],\n",
       "                        [-3.7981e-02, -7.2602e-02,  7.3979e-02]],\n",
       "              \n",
       "                       [[-9.2218e-02, -3.0835e-02,  4.9549e-02],\n",
       "                        [-2.2612e-02,  1.8590e-02,  1.2959e-02],\n",
       "                        [-5.3542e-02, -7.1420e-02, -5.2794e-02]]]])),\n",
       "             ('convs.2.bias',\n",
       "              tensor([-0.0025, -0.0071, -0.0043, -0.0005,  0.0014,  0.0045, -0.0008,  0.0003,\n",
       "                      -0.0002,  0.0016,  0.0008,  0.0045,  0.0004, -0.0061, -0.0013, -0.0024,\n",
       "                       0.0013, -0.0043, -0.0044, -0.0024,  0.0002, -0.0022,  0.0022,  0.0023,\n",
       "                       0.0037, -0.0033, -0.0017,  0.0012,  0.0014, -0.0055, -0.0041, -0.0026,\n",
       "                      -0.0041,  0.0001, -0.0022, -0.0003, -0.0062, -0.0005,  0.0006,  0.0012,\n",
       "                       0.0004, -0.0032, -0.0022,  0.0029, -0.0029, -0.0088, -0.0027, -0.0011,\n",
       "                      -0.0023, -0.0020, -0.0037, -0.0009, -0.0015, -0.0079, -0.0011, -0.0044,\n",
       "                      -0.0027, -0.0027, -0.0018, -0.0053, -0.0081, -0.0011, -0.0031, -0.0015,\n",
       "                      -0.0004, -0.0055, -0.0070, -0.0019,  0.0025,  0.0005, -0.0051,  0.0008,\n",
       "                      -0.0043, -0.0034, -0.0038,  0.0069, -0.0011,  0.0008, -0.0064, -0.0036,\n",
       "                      -0.0039, -0.0036,  0.0045, -0.0022, -0.0045, -0.0013,  0.0027, -0.0038,\n",
       "                       0.0004,  0.0016, -0.0029, -0.0019,  0.0031, -0.0019, -0.0080, -0.0046,\n",
       "                      -0.0026,  0.0006, -0.0024])),\n",
       "             ('convs.3.weight',\n",
       "              tensor([[[[ 5.1981e-03, -1.9214e-02,  3.8033e-02],\n",
       "                        [-4.3396e-02,  1.0031e-01,  2.1311e-02],\n",
       "                        [ 5.9902e-02,  9.3106e-02,  4.9288e-03]],\n",
       "              \n",
       "                       [[ 6.8411e-02, -8.8972e-03, -8.4404e-02],\n",
       "                        [-5.8486e-02, -2.2696e-02,  6.8178e-02],\n",
       "                        [ 2.2817e-02,  4.8532e-02, -1.1356e-02]],\n",
       "              \n",
       "                       [[-4.1885e-02, -3.4849e-03, -2.6865e-02],\n",
       "                        [ 1.4889e-02, -8.7436e-02,  4.2506e-02],\n",
       "                        [-7.1608e-02, -7.5173e-02,  2.5941e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8337e-02, -3.1763e-02,  2.0407e-02],\n",
       "                        [-3.3254e-03, -5.4051e-02, -4.3561e-02],\n",
       "                        [ 4.3003e-02, -4.9221e-02,  5.4048e-04]],\n",
       "              \n",
       "                       [[ 2.9834e-02, -6.8913e-02, -3.2161e-02],\n",
       "                        [-6.0391e-02,  6.8195e-02, -5.3618e-02],\n",
       "                        [-8.8452e-02, -1.2673e-02,  5.0019e-03]],\n",
       "              \n",
       "                       [[ 1.8864e-02,  2.1990e-02, -5.2600e-02],\n",
       "                        [ 2.5437e-02, -6.5711e-02, -2.5709e-02],\n",
       "                        [ 5.5309e-02,  2.5642e-02,  1.9377e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8994e-02, -7.4016e-02,  3.9514e-02],\n",
       "                        [ 2.0824e-03, -4.0957e-02,  4.2271e-02],\n",
       "                        [-2.7650e-02, -4.9448e-02, -3.2254e-02]],\n",
       "              \n",
       "                       [[ 7.7314e-03,  4.6638e-02, -4.5026e-02],\n",
       "                        [-7.4117e-03, -6.5434e-02,  9.7255e-02],\n",
       "                        [-5.8798e-03,  4.6824e-02,  2.0050e-02]],\n",
       "              \n",
       "                       [[-7.4790e-02, -3.2956e-02, -7.7016e-03],\n",
       "                        [ 2.5381e-02, -5.5653e-02, -6.5064e-02],\n",
       "                        [ 2.0266e-02, -2.5808e-03, -5.2820e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.3724e-02, -2.0719e-02,  1.6687e-02],\n",
       "                        [ 6.0865e-03, -1.2004e-02, -7.0612e-03],\n",
       "                        [-9.9308e-02, -6.6240e-02, -6.7440e-02]],\n",
       "              \n",
       "                       [[-8.9360e-02, -2.8362e-03, -1.7378e-02],\n",
       "                        [ 1.6695e-02, -5.0556e-02,  5.4702e-02],\n",
       "                        [ 7.3403e-02, -2.7290e-03, -1.0001e-01]],\n",
       "              \n",
       "                       [[-2.9796e-02, -3.1377e-02, -3.4212e-02],\n",
       "                        [-6.2812e-02,  1.6719e-02,  2.0021e-02],\n",
       "                        [-3.3085e-02, -6.3127e-02,  9.3179e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1357e-02,  5.6667e-02,  6.3048e-02],\n",
       "                        [ 5.2167e-02,  5.3683e-02,  6.5913e-02],\n",
       "                        [-1.8632e-02,  5.7456e-03, -1.5314e-02]],\n",
       "              \n",
       "                       [[ 2.3225e-02, -2.5012e-02, -1.1447e-02],\n",
       "                        [ 5.0845e-02, -7.8683e-02,  4.6066e-02],\n",
       "                        [ 4.2624e-02, -8.5832e-02,  6.5720e-02]],\n",
       "              \n",
       "                       [[-3.6267e-02,  6.3575e-02,  4.9567e-02],\n",
       "                        [ 1.7035e-04,  1.3252e-02, -3.6379e-02],\n",
       "                        [ 1.5520e-02,  2.8218e-03, -1.5136e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.3828e-02, -5.9674e-02,  8.4794e-02],\n",
       "                        [ 7.0373e-02,  1.9693e-02,  1.6993e-02],\n",
       "                        [-8.5625e-02,  4.2555e-02, -6.0067e-02]],\n",
       "              \n",
       "                       [[-2.1271e-02,  2.4298e-02,  2.9026e-02],\n",
       "                        [ 3.1619e-02, -4.7451e-02,  1.1671e-01],\n",
       "                        [-9.7514e-03, -1.1172e-01,  1.5235e-02]],\n",
       "              \n",
       "                       [[ 3.2342e-02,  2.6156e-02, -2.1061e-02],\n",
       "                        [ 1.7280e-02,  1.8572e-02,  5.1014e-02],\n",
       "                        [ 7.2850e-02,  4.6486e-02,  8.1099e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0540e-02,  4.2645e-02,  3.2302e-02],\n",
       "                        [-2.9888e-02,  7.2210e-02,  2.1428e-02],\n",
       "                        [ 4.6192e-02, -5.9942e-02, -4.4915e-02]],\n",
       "              \n",
       "                       [[-1.9389e-03,  3.7524e-02, -8.2961e-02],\n",
       "                        [-3.2350e-02, -7.1715e-02, -4.3529e-02],\n",
       "                        [-2.9899e-02, -6.9911e-02,  2.8457e-02]],\n",
       "              \n",
       "                       [[ 7.2025e-02, -6.2742e-02,  7.2068e-02],\n",
       "                        [ 6.0373e-02, -1.0075e-01,  4.5399e-02],\n",
       "                        [-1.7786e-02,  7.6910e-02, -1.2110e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.6501e-02,  1.8433e-02,  3.5947e-02],\n",
       "                        [ 1.5218e-02,  6.8505e-02,  2.5066e-02],\n",
       "                        [ 5.6750e-02, -3.7344e-02, -5.0480e-02]],\n",
       "              \n",
       "                       [[-2.7779e-02,  6.3876e-03, -1.6684e-02],\n",
       "                        [ 3.4774e-02, -3.9915e-02,  2.4280e-02],\n",
       "                        [ 1.2587e-02,  1.1151e-02,  1.4180e-02]],\n",
       "              \n",
       "                       [[-4.1398e-02,  2.3447e-02, -1.8224e-02],\n",
       "                        [-6.8160e-03, -1.9319e-02, -3.0533e-02],\n",
       "                        [ 9.7226e-02, -1.8801e-02,  7.3076e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.8504e-02,  6.1330e-03,  3.2882e-02],\n",
       "                        [ 5.0680e-02, -4.2598e-02,  7.2675e-02],\n",
       "                        [-3.4759e-02,  4.3179e-02, -7.5507e-03]],\n",
       "              \n",
       "                       [[ 4.9176e-04,  1.1106e-01, -4.9193e-05],\n",
       "                        [-3.9230e-02,  2.5127e-02, -3.2638e-02],\n",
       "                        [-1.0229e-01,  2.1581e-02, -1.0904e-02]],\n",
       "              \n",
       "                       [[-1.2739e-01,  5.7198e-03,  3.4540e-02],\n",
       "                        [-4.0446e-02, -1.6861e-02,  7.8067e-03],\n",
       "                        [ 7.7505e-02,  3.0442e-02, -1.9445e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2200e-03,  2.4826e-02,  6.0364e-03],\n",
       "                        [ 1.2660e-02,  3.0827e-02,  5.6028e-02],\n",
       "                        [-9.1355e-02,  1.8546e-02, -1.6075e-03]],\n",
       "              \n",
       "                       [[-2.9000e-02, -7.7795e-02, -7.6120e-02],\n",
       "                        [-3.3921e-02, -1.0972e-01, -3.4725e-02],\n",
       "                        [-2.9204e-03,  4.1448e-02,  5.9495e-02]],\n",
       "              \n",
       "                       [[ 2.4187e-02, -3.1036e-02, -3.5662e-02],\n",
       "                        [ 5.2555e-02,  1.2638e-01,  5.7338e-02],\n",
       "                        [ 5.6644e-02,  4.4960e-02, -2.5945e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.6789e-02, -4.2431e-02, -9.5410e-02],\n",
       "                        [-3.6892e-02, -2.0009e-02, -5.7996e-02],\n",
       "                        [-4.6361e-02, -5.3381e-03, -1.7744e-02]],\n",
       "              \n",
       "                       [[-9.8346e-02,  4.9487e-02, -7.5206e-02],\n",
       "                        [-1.5096e-02,  1.4218e-02,  7.5293e-02],\n",
       "                        [ 4.1548e-02, -1.5754e-02, -4.0047e-02]],\n",
       "              \n",
       "                       [[ 1.5975e-02, -3.3788e-02,  5.0220e-02],\n",
       "                        [-1.2614e-02, -4.6745e-04, -5.1727e-02],\n",
       "                        [ 5.3238e-02,  4.5295e-02,  3.8593e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2632e-02, -1.2194e-03,  2.6687e-02],\n",
       "                        [-1.7366e-02,  5.4235e-02,  3.6868e-02],\n",
       "                        [-8.0582e-02, -1.3321e-02, -1.4832e-02]],\n",
       "              \n",
       "                       [[-9.7489e-02, -3.2068e-03, -1.1098e-01],\n",
       "                        [ 2.9932e-02,  6.8240e-02,  4.7612e-02],\n",
       "                        [ 6.2117e-02,  3.6085e-02,  2.9385e-02]],\n",
       "              \n",
       "                       [[-3.8458e-02, -1.7081e-02,  7.5473e-03],\n",
       "                        [ 6.3660e-03, -1.1522e-02, -2.1259e-03],\n",
       "                        [-5.0687e-02, -4.7536e-02, -6.5003e-02]]]])),\n",
       "             ('convs.3.bias',\n",
       "              tensor([-5.3435e-03, -2.6620e-03, -1.2786e-03,  3.1172e-03, -8.0471e-04,\n",
       "                      -9.8911e-04, -3.4818e-03, -4.0804e-04, -1.3402e-03,  2.9847e-04,\n",
       "                      -4.6412e-03,  1.8950e-03, -4.9169e-03, -3.9046e-03, -1.4659e-03,\n",
       "                      -2.3852e-03,  7.0017e-05,  2.1627e-03, -1.5779e-03,  2.8650e-03,\n",
       "                       1.4349e-04,  4.7880e-04, -2.3117e-03, -1.4980e-03, -2.8406e-03,\n",
       "                       4.9518e-03, -1.2167e-03, -2.0220e-03, -2.4397e-03, -5.2422e-03,\n",
       "                      -2.1185e-04,  2.8353e-03,  2.4689e-03, -5.5955e-03, -2.7537e-03,\n",
       "                      -1.7494e-03,  1.8322e-03, -2.6263e-03, -2.5663e-03, -1.1656e-03,\n",
       "                      -4.8563e-03, -5.9243e-03, -2.7786e-03, -2.3435e-03, -1.8498e-03,\n",
       "                      -4.4474e-03, -4.2120e-04, -3.6891e-03, -3.2064e-03, -8.7503e-04,\n",
       "                      -2.2713e-03,  2.3337e-03, -1.4544e-03, -4.0631e-05, -3.9784e-03,\n",
       "                      -4.9802e-03, -3.9252e-03, -1.3662e-03, -5.3852e-03, -3.0440e-03,\n",
       "                       1.4000e-04, -7.8702e-04, -5.5398e-03, -2.9640e-03, -1.9959e-03,\n",
       "                      -4.6196e-03, -9.0214e-05, -2.9925e-03,  3.0756e-03, -1.1654e-03,\n",
       "                      -4.3275e-03, -1.8869e-03, -3.9954e-03, -4.1629e-03, -2.9152e-03,\n",
       "                      -2.3385e-03, -3.3329e-03, -2.5535e-03,  2.0822e-03, -3.3627e-03,\n",
       "                      -1.3282e-03, -1.0824e-03])),\n",
       "             ('fc1.weight',\n",
       "              tensor([[ 0.0128,  0.0240,  0.0007,  ...,  0.0048, -0.0024,  0.0024],\n",
       "                      [-0.0150, -0.0134, -0.0042,  ...,  0.0162, -0.0012, -0.0086],\n",
       "                      [-0.0074,  0.0094,  0.0114,  ..., -0.0054,  0.0020, -0.0139],\n",
       "                      ...,\n",
       "                      [-0.0095, -0.0181, -0.0102,  ..., -0.0054,  0.0022,  0.0080],\n",
       "                      [ 0.0068,  0.0105,  0.0131,  ...,  0.0091,  0.0073, -0.0075],\n",
       "                      [-0.0080, -0.0048,  0.0219,  ..., -0.0137,  0.0033, -0.0002]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-4.7324e-04, -6.3591e-03,  6.7103e-03, -3.9498e-03,  4.6195e-03,\n",
       "                       1.1563e-04,  5.1546e-04, -8.3317e-04, -1.3299e-03, -7.6662e-03,\n",
       "                       4.0531e-03,  5.0084e-03,  5.7696e-03,  5.9821e-03, -6.2650e-03,\n",
       "                       3.0117e-03,  1.6791e-03, -9.6449e-03,  4.4815e-03,  4.6775e-03,\n",
       "                      -1.1401e-03, -2.8635e-04, -7.1624e-03,  4.3096e-03, -1.4275e-03,\n",
       "                       7.8684e-03,  4.2696e-03,  5.7420e-03, -4.9262e-03,  4.5785e-03,\n",
       "                       4.8756e-03,  3.9111e-03,  3.7481e-03, -3.1851e-04,  6.4131e-03,\n",
       "                      -2.2326e-03, -2.0732e-03, -1.2510e-04, -3.2197e-04, -2.2732e-03,\n",
       "                      -1.2223e-03,  4.5270e-03, -5.0396e-03, -5.4074e-03,  3.8946e-03,\n",
       "                      -2.0157e-03, -4.0883e-03, -2.8767e-03,  9.9404e-04,  4.6185e-03,\n",
       "                       1.0164e-02,  9.9074e-03,  5.4401e-03,  6.8974e-03,  3.1594e-03,\n",
       "                       1.3512e-02,  4.9837e-03, -6.0260e-03,  1.9102e-03,  3.8380e-03,\n",
       "                       4.5565e-03,  1.2805e-03,  4.8574e-03, -5.3588e-04, -2.1913e-03,\n",
       "                      -2.2675e-04, -6.8617e-03,  1.0174e-02, -1.9854e-03,  8.7013e-03,\n",
       "                      -5.9936e-03, -1.2947e-03, -4.7111e-03, -6.3904e-03,  3.9441e-03,\n",
       "                      -1.7064e-03, -5.6915e-03, -1.8383e-03,  4.0486e-03,  4.2602e-03,\n",
       "                      -7.0331e-04,  9.4061e-03,  6.2121e-03,  6.1929e-03, -1.4669e-03,\n",
       "                      -3.4632e-03,  4.8011e-03,  7.4001e-03,  9.3880e-03, -7.6560e-03,\n",
       "                      -1.8922e-03,  6.3188e-03,  1.0930e-02,  1.0985e-02, -7.3507e-05,\n",
       "                       2.6027e-03, -5.2146e-03, -1.0724e-02, -5.4176e-03,  1.5321e-03,\n",
       "                      -2.0645e-03,  5.5978e-03,  4.3499e-03, -5.9046e-03,  7.1909e-04,\n",
       "                      -6.7779e-03,  7.9632e-04, -3.1733e-03, -4.5746e-03,  2.0556e-03,\n",
       "                       5.6660e-03,  6.5283e-03,  7.3310e-03, -1.0233e-02, -3.8885e-03,\n",
       "                      -1.0507e-02,  5.5729e-03,  3.8459e-03, -1.9122e-03,  9.1823e-03,\n",
       "                      -7.0330e-04,  6.2944e-03,  5.9729e-03, -5.2197e-03, -1.8066e-03,\n",
       "                       5.3059e-03,  3.7048e-03, -7.2043e-04, -2.2740e-03,  2.2301e-03,\n",
       "                      -1.6585e-03, -1.7920e-03,  5.3953e-03, -1.8374e-03, -6.4373e-03,\n",
       "                       3.0085e-03, -1.2224e-03, -2.5638e-03,  9.1073e-03, -2.5118e-03,\n",
       "                      -6.5375e-03, -2.4147e-03, -2.1825e-03, -2.8239e-03,  6.0902e-03,\n",
       "                       8.4410e-03, -8.7455e-05,  5.0112e-03,  9.1231e-04,  8.1889e-03,\n",
       "                       1.9056e-03,  4.6939e-03, -5.6531e-03,  1.1316e-02,  1.2715e-03,\n",
       "                      -2.7509e-03, -7.2369e-03, -5.6988e-03, -1.2421e-03, -3.9357e-03,\n",
       "                       2.4449e-03,  7.0815e-04, -2.3788e-03, -6.5691e-03, -6.5017e-03,\n",
       "                      -1.5352e-05, -5.5604e-03, -5.4212e-03,  3.7716e-04, -2.6836e-03,\n",
       "                      -9.3501e-03, -7.4774e-03, -5.2657e-03, -3.6478e-03,  1.3975e-03,\n",
       "                      -7.3926e-03, -8.5872e-03,  5.3363e-03,  9.9573e-03, -9.9213e-03,\n",
       "                      -7.5409e-04,  3.6722e-03,  1.0228e-03, -1.4230e-03,  6.6945e-03,\n",
       "                      -7.9487e-04, -8.4618e-03, -5.0475e-03, -2.7713e-03,  2.8380e-03,\n",
       "                       9.8030e-03,  4.3999e-03, -2.2256e-03,  6.3755e-03, -7.0052e-03,\n",
       "                       4.8222e-03, -8.3108e-04, -5.2524e-04,  5.5717e-03,  1.3059e-03,\n",
       "                      -2.7234e-03,  2.1160e-03, -4.9462e-03,  5.0868e-03, -7.3866e-03,\n",
       "                      -7.5261e-03, -5.5405e-03, -3.5751e-03, -1.1025e-03,  5.2735e-03,\n",
       "                       4.4715e-03,  2.3092e-03,  8.8031e-03, -5.2506e-03, -5.6613e-03,\n",
       "                      -5.4538e-05,  2.2489e-03,  6.4644e-03,  5.2804e-04,  3.6959e-03,\n",
       "                      -4.0034e-03,  4.6321e-03,  6.6213e-03,  3.4506e-04,  6.4594e-04,\n",
       "                      -4.3758e-03,  4.9448e-04, -3.6510e-03,  3.0861e-03,  1.1690e-03,\n",
       "                      -3.1863e-04, -3.9182e-03, -2.9972e-03,  8.0394e-04,  4.3153e-03,\n",
       "                       9.0332e-04,  1.5318e-03, -4.4583e-03,  9.8499e-03, -5.0187e-03,\n",
       "                       3.7735e-03, -1.7367e-03,  5.6861e-03, -6.0073e-03, -4.3300e-04,\n",
       "                      -5.6551e-03, -4.2063e-03, -4.0380e-03,  5.1863e-03,  4.0398e-03,\n",
       "                      -8.5878e-03, -9.2689e-04,  1.0081e-03,  2.4758e-03, -3.3036e-04,\n",
       "                      -8.5097e-03,  1.0643e-02,  2.0436e-03, -9.9282e-04, -4.1008e-04,\n",
       "                      -8.6141e-03, -3.6601e-03, -7.0143e-04, -4.2160e-04, -7.5533e-03,\n",
       "                      -4.6226e-03, -3.2906e-03,  8.4213e-04,  1.5140e-03, -1.3442e-03,\n",
       "                      -1.0293e-03,  1.2055e-02,  4.4791e-03,  3.4525e-03,  2.7849e-05,\n",
       "                      -7.3200e-04,  5.8643e-03,  2.6420e-03, -7.5612e-05,  5.2342e-03,\n",
       "                      -3.3614e-04, -1.1293e-02,  4.1726e-03,  6.3695e-03,  4.6946e-03,\n",
       "                      -8.6550e-03, -3.4721e-03,  2.5224e-03, -3.6629e-03,  1.1417e-02,\n",
       "                       2.9284e-03, -7.0360e-03, -4.2107e-03, -2.2318e-04,  2.9785e-03,\n",
       "                       9.7727e-04,  8.2176e-03, -1.4596e-03, -6.7310e-04,  2.1191e-03,\n",
       "                       2.6652e-03, -4.4762e-03, -2.9991e-03, -7.2932e-04, -5.1811e-03,\n",
       "                      -2.8622e-03,  6.0869e-03,  7.7719e-03, -3.5479e-04,  4.4533e-03,\n",
       "                      -2.4443e-05,  5.4431e-04, -2.3771e-04,  3.5831e-03,  4.3469e-03,\n",
       "                       8.4885e-04,  4.6118e-03, -4.9266e-03, -7.4326e-03, -4.9149e-03,\n",
       "                       2.9356e-03,  6.1292e-03,  6.6959e-03,  8.1400e-03,  2.1547e-03,\n",
       "                      -2.2957e-03, -8.4293e-04,  3.1467e-03,  1.0544e-03, -3.5493e-03,\n",
       "                      -4.7199e-03,  8.5043e-05, -1.5720e-03,  2.6939e-03, -4.8311e-03,\n",
       "                      -6.0070e-03, -8.3327e-03])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0048, -0.0052, -0.0284,  ...,  0.0186, -0.0500,  0.0420],\n",
       "                      [-0.0477,  0.0058, -0.0500,  ..., -0.0412, -0.0019, -0.0414],\n",
       "                      [ 0.0289,  0.0259,  0.0025,  ..., -0.0271, -0.0027, -0.0385],\n",
       "                      ...,\n",
       "                      [ 0.0092,  0.0377, -0.0356,  ..., -0.0367, -0.0132,  0.0435],\n",
       "                      [-0.0504,  0.0194, -0.0097,  ...,  0.0134, -0.0218, -0.0087],\n",
       "                      [-0.0301, -0.0240, -0.0159,  ...,  0.0112,  0.0153, -0.0349]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0326,  0.0183, -0.0246, -0.0125,  0.0426,  0.0503,  0.0530, -0.0011,\n",
       "                       0.0340, -0.0168]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b62bd068",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bfbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
